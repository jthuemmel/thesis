{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51b8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch\n",
    "\n",
    "from einops.layers.torch import EinMix\n",
    "\n",
    "from utils.components import *\n",
    "from utils.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee1c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "world = WorldConfig(field_sizes={\"v\": 6, \"t\": 36, \"h\": 64, \"w\": 120}, patch_sizes={'vv': 2, 'tt': 6, 'hh': 4, 'ww': 4}, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34badbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NetworkConfig(dim=256, num_latents=32, num_layers=12, num_cls=4, use_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b97cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in = EinMix(pattern=f\"{world.field_pattern} -> b {world.flat_token_pattern} d\", \n",
    "              weight_shape=f'v d {world.patch_pattern}', \n",
    "              bias_shape=f'{world.flat_token_pattern} d',\n",
    "              **world.patch_sizes, **world.token_sizes, d = network.dim\n",
    "              )\n",
    "\n",
    "test_out = EinMix(\n",
    "            pattern=f\"b {world.flat_token_pattern} d -> {world.field_pattern} e\", \n",
    "            weight_shape=f'e v {world.patch_pattern} d', \n",
    "            bias_shape=f'e v {world.patch_pattern}',\n",
    "            **world.patch_sizes, **world.token_sizes, d = network.dim, e = network.num_cls\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1cc7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6, 36, 64, 120])\n",
      "torch.Size([16, 8640, 256])\n",
      "torch.Size([16, 6, 36, 64, 120, 4])\n",
      "torch.Size([3, 256, 2, 6, 4, 4])\n",
      "torch.Size([1, 3, 6, 16, 30, 256])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((world.batch_size, world.field_sizes['v'], world.field_sizes['t'], world.field_sizes['h'], world.field_sizes['w']))\n",
    "b = test_in(a)\n",
    "c = test_out(b)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "\n",
    "print(test_in.weight.shape)\n",
    "print(test_in.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab828536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EinMask(torch.nn.Module):\n",
    "    def __init__(self, network: NetworkConfig, world: WorldConfig):\n",
    "        super().__init__()\n",
    "        # I/O\n",
    "        self.to_tokens = EinMix(\n",
    "            pattern=f\"{world.field_pattern} -> b {world.flat_token_pattern} d\", \n",
    "            weight_shape=f'v d {world.patch_pattern}', \n",
    "            bias_shape=f'{world.flat_token_pattern} d',\n",
    "            **world.patch_sizes, **world.token_sizes, \n",
    "            d = network.dim\n",
    "            )\n",
    "        \n",
    "        self.to_fields = EinMix(\n",
    "            pattern=f\"b {world.flat_token_pattern} d -> {world.field_pattern} e\", \n",
    "            weight_shape=f'e v {world.patch_pattern} d', \n",
    "            bias_shape=f'e v {world.patch_pattern}',\n",
    "            **world.patch_sizes, **world.token_sizes, \n",
    "            d = network.dim, e = network.num_cls\n",
    "            )\n",
    "        \n",
    "        # embeddings\n",
    "        self.latents = torch.nn.Embedding(network.num_latents, network.dim)\n",
    "        self.queries = torch.nn.Embedding(world.num_tokens, network.dim)\n",
    "\n",
    "        # perceiver\n",
    "        self.transformer = torch.nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                dim =network.dim, \n",
    "                dim_heads=network.dim_heads, \n",
    "                dim_ctx = network.dim_noise\n",
    "                ) for _ in range(network.num_layers)\n",
    "            ])\n",
    "        self.write = TransformerBlock(\n",
    "                dim =network.dim, \n",
    "                dim_heads=network.dim_heads, \n",
    "                dim_ctx = network.dim_noise\n",
    "                )\n",
    "\n",
    "        # Weight initialization\n",
    "        self.apply(self.base_init)\n",
    "    \n",
    "    @staticmethod\n",
    "    def base_init(m):\n",
    "        '''Explicit weight initialization for all components'''\n",
    "        # linear\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            torch.nn.init.trunc_normal_(m.weight, std = get_weight_std(m.weight))\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "        # embedding\n",
    "        if isinstance(m, torch.nn.Embedding):\n",
    "            torch.nn.init.trunc_normal_(m.weight, std = get_weight_std(m.weight))\n",
    "        # einmix\n",
    "        if isinstance(m, EinMix):\n",
    "            torch.nn.init.trunc_normal_(m.weight, std = 0.02)\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "        # conditional layer norm\n",
    "        if isinstance(m, ConditionalLayerNorm):\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "            if m.weight is not None: # CLN weight close to 0\n",
    "                torch.nn.init.trunc_normal_(m.weight, std = 1e-7)\n",
    "\n",
    "    def forward(self, fields, context):\n",
    "        # project field to tokens\n",
    "        x = self.to_tokens(fields)\n",
    "        # expand shapes\n",
    "        z = einops.repeat(self.latents.weight, 'm d -> b m d', b = x.size(0))\n",
    "        q = einops.repeat(self.queries.weight, 'n d -> b n d', b = x.size(0))\n",
    "        c = einops.repeat(context, 'b n -> b n d', d = x.size(-1))\n",
    "        # gather context\n",
    "        x = x.gather(1, c)\n",
    "        # apply transformer\n",
    "        for block in self.transformer:\n",
    "            kv = torch.cat([x, z], dim = 1)\n",
    "            z = block(q = z, kv = kv)\n",
    "        q = self.write(q = q, kv = z)\n",
    "        # return field\n",
    "        fields = self.to_fields(q)\n",
    "        return fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f9dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b22d1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichlet = torch._sample_dirichlet(torch.full((world.batch_size, world.token_sizes['t']), 0.5))\n",
    "prior = einops.repeat(dirichlet, f'b t -> b {world.flat_token_pattern}', **world.token_sizes)\n",
    "k = torch.randint(128, 4096, (1,)).item()\n",
    "src = torch.multinomial(prior, k)\n",
    "mask = torch.ones_like(prior, dtype= torch.bool).scatter_(1, src, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2c9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EinMask(network, world).to(\"cuda\")\n",
    "a = torch.randn((world.batch_size, world.field_sizes['v'], world.field_sizes['t'], world.field_sizes['h'], world.field_sizes['w']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a614a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.amp.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "    d = model(a.to(\"cuda\"), src.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36743e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
