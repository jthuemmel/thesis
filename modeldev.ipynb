{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.nn import Module, ModuleList, Embedding, Linear\n",
    "from torch.nn.init import trunc_normal_, zeros_\n",
    "from einops import rearrange, reduce, repeat\n",
    "from utils.components import TransformerBlock, ConditionalLayerNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6b881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModalEncoder(Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.in_projection = Embedding(cfg.num_features, cfg.dim * cfg.dim_input)\n",
    "        self.feature_bias = Embedding(cfg.num_features, cfg.dim)\n",
    "        self.queries = Embedding(1, cfg.dim)       \n",
    "        self.kv_norm = ConditionalLayerNorm(cfg.dim, cfg.dim_ctx)\n",
    "        self.cross_attn = TransformerBlock(cfg.dim, dim_ctx=cfg.dim_ctx)\n",
    "\n",
    "    def forward(self, data, idx, ctx = None):\n",
    "        # ensure correct shapes\n",
    "        B, N, _, I = data.size()\n",
    "        # get dynamic weights \n",
    "        w = self.in_projection(idx)\n",
    "        w = rearrange(w, '... f (d i) -> ... f d i', i = I)\n",
    "        # linear projection\n",
    "        kv = torch.einsum('b n f i, ... f d i -> b n f d', data, w)\n",
    "        # normalize and add feature-bias\n",
    "        kv = self.kv_norm(kv, ctx) + self.feature_bias(idx)\n",
    "        # expand query vectors\n",
    "        q = repeat(self.queries.weight, 'q d -> b n q d', b = B, n = N)\n",
    "        # cross attend\n",
    "        q = self.cross_attn(q = q, kv = kv, ctx = ctx).squeeze(2)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # Embeddings\n",
    "        self.out_projection = Embedding(cfg.num_features, cfg.dim * cfg.dim_output)\n",
    "\n",
    "        self.positions = Embedding(cfg.num_positions, cfg.dim)\n",
    "        \n",
    "        self.queries = Embedding(cfg.num_latents, cfg.dim)\n",
    "\n",
    "        # Networks\n",
    "        self.encoder = ModalEncoder(cfg)\n",
    "        self.processor = ModuleList([TransformerBlock(cfg.dim, dim_ctx=cfg.dim_ctx) for _ in range(cfg.num_blocks)])\n",
    "\n",
    "        # Init\n",
    "        self.apply(self.base_init)\n",
    "        self.apply(self.zero_init)\n",
    "\n",
    "    @staticmethod\n",
    "    def base_init(m):\n",
    "        if isinstance(m, Linear):\n",
    "            trunc_normal_(m, std = 0.02)\n",
    "        if isinstance(m, Embedding):\n",
    "            trunc_normal_(m, std = 0.02)\n",
    "\n",
    "    @staticmethod\n",
    "    def zero_init(m):\n",
    "        if isinstance(m, TransformerBlock):\n",
    "            zeros_(m.att.to_out.weight)\n",
    "            zeros_(m.ffn.to_out.weight)\n",
    "            zeros_(m.att_norm.to_out.weight)\n",
    "            zeros_(m.ffn_norm.to_out.weight)\n",
    "        \n",
    "\n",
    "    def forward(self, data, coords, noise):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51b529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
