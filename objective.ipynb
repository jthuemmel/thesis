{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91298168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import math\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from utils.model import *\n",
    "from utils.config import NetworkConfig\n",
    "from utils.loss_fn import f_kernel_crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f93ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4339d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WorldConfig:\n",
    "    field_layout: tuple\n",
    "    patch_layout: tuple\n",
    "    field_sizes: dict\n",
    "    patch_sizes: dict\n",
    "    batch_size: int\n",
    "    tau: int\n",
    "    alphas: dict\n",
    "    mask_range: tuple\n",
    "    loss_weights: dict\n",
    "\n",
    "@dataclass\n",
    "class ConfigWrapper:\n",
    "    world : WorldConfig\n",
    "    network : NetworkConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = NetworkConfig(\n",
    "    dim = 256, \n",
    "    num_layers=4, \n",
    "    num_compute_blocks=4,\n",
    "    dim_in = 480,\n",
    "    dim_out = 960,\n",
    "    dim_coords = 128,\n",
    "    wavelengths=[(1e-3, 1e2,), (1e-3, 1e2), (1e-3, 1e2,), (1e-3, 1e2,)], \n",
    "    num_features= 9, \n",
    "    num_latents=64)\n",
    "\n",
    "world_cfg = WorldConfig(\n",
    "    field_layout = ('v', 't', 'h', 'w'),\n",
    "    patch_layout = ('vv', 'tt', 'hh', 'ww'),\n",
    "    field_sizes = {'v': 9, 't': 36, 'h': 64, 'w': 120},\n",
    "    patch_sizes = {'vv': 1, 'tt': 6, 'hh': 8, 'ww': 10},\n",
    "    batch_size = 8,\n",
    "    tau = 2,\n",
    "    alphas = {'t': 0.5},\n",
    "\n",
    "    loss_weights = {'temp_ocn_0a': 1.,\n",
    "               'temp_ocn_1a': 0.1,\n",
    "               'temp_ocn_3a': 0.1,\n",
    "               'temp_ocn_5a': 0.1,\n",
    "               'temp_ocn_8a': 0.1,\n",
    "               'temp_ocn_11a': 0.1,\n",
    "               'temp_ocn_14a': 0.1,\n",
    "               'tauxa': 0.01,\n",
    "               'tauya': 0.01,\n",
    "        }\n",
    ")\n",
    "\n",
    "cfg = ConfigWrapper(\n",
    "    world = world_cfg,\n",
    "    network = model_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a24638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedField(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self._cfg = cfg.world\n",
    "        self.device_type: str = 'cpu'\n",
    "        self.device: torch.DeviceObjType = torch.device('cpu')\n",
    "        self.network = MaskedTokenField(cfg.network)\n",
    "\n",
    "    ### SHAPES\n",
    "    @property # arrangement of axes in the unpatched field \n",
    "    def field_layout(self): \n",
    "        return self._cfg.field_layout\n",
    "    \n",
    "    @property # arrangement of axes in the patch dimension\n",
    "    def patch_layout(self): \n",
    "        return self._cfg.patch_layout\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self): \n",
    "        return self._cfg.batch_size\n",
    "\n",
    "    @property # field sizes per axis from config\n",
    "    def field_sizes(self): \n",
    "        return self._cfg.field_sizes\n",
    "\n",
    "    @property # patch sizes per axis from config\n",
    "    def patch_sizes(self): \n",
    "        return self._cfg.patch_sizes\n",
    "    \n",
    "    @property # patch counts per axis derived from field and patch sizes\n",
    "    def token_sizes(self): \n",
    "        return {ax: (self.field_sizes[ax] // self.patch_sizes[f'{ax*2}']) for ax in self.field_layout}\n",
    "    \n",
    "    @property # tuple of integers for the patched dimensions\n",
    "    def token_shape(self):\n",
    "        return tuple(self.token_sizes[ax] for ax in self.field_layout)\n",
    "    \n",
    "    @property # total number of patches in the flatland representation\n",
    "    def num_tokens(self): \n",
    "        return math.prod([self.token_sizes[t] for t in self.field_layout])\n",
    "\n",
    "    @property # total number of values in a single patch\n",
    "    def dim_tokens(self):  \n",
    "        return math.prod([self.patch_sizes[p] for p in self.patch_layout])\n",
    "\n",
    "    @property # einops pattern for the unpatched field\n",
    "    def field_pattern(self): \n",
    "        field = \" \".join([f\"({f} {p})\" for f, p in zip(self.field_layout, self.patch_layout)])\n",
    "        return f\"b {field}\"\n",
    "\n",
    "    @property # einops pattern for the flattened token dimension\n",
    "    def flat_token_pattern(self):\n",
    "        return f'({' '.join(self.field_layout)})'\n",
    "    \n",
    "    @property # einops pattern for the flattened patch dimension\n",
    "    def flat_patch_pattern(self):\n",
    "        return f'({' '.join(self.patch_layout)})'\n",
    "\n",
    "    @property # einops pattern for the patched flatland representation\n",
    "    def flatland_pattern(self): \n",
    "        return f'b {self.flat_token_pattern} {self.flat_patch_pattern}'\n",
    "    \n",
    "    @property # (batched) indices for all tokens in flatland representation\n",
    "    def flatland_index(self):\n",
    "        return torch.arange(self.num_tokens, device = self.device).expand(self.batch_size, -1)\n",
    "    \n",
    "    @property # (batched) indices for all tokens in field representation\n",
    "    def token_index(self):\n",
    "        return torch.stack(torch.unravel_index(self.flatland_index, self.token_shape), dim = -1)\n",
    "\n",
    "    ### TOKENIZATION\n",
    "    def field_to_tokens(self, field):\n",
    "        return einops.rearrange(field, f'{self.field_pattern} -> {self.flatland_pattern}', **self.patch_sizes)\n",
    "    \n",
    "    def tokens_to_field(self, patch):\n",
    "        return einops.rearrange(patch, f\"{self.flatland_pattern} ... -> {self.field_pattern} ...\", **self.token_sizes, **self.patch_sizes)\n",
    "\n",
    "    ### MASKING\n",
    "    def gumbel_noise(self, shape: tuple, eps: float = 1e-6):\n",
    "        u = torch.rand(shape, device = self.device).clamp(min=eps, max=1-eps)\n",
    "        return -torch.log(-torch.log(u))\n",
    "            \n",
    "    def dirichlet_marginal(self, ax: str):\n",
    "        concentration = torch.full((self.batch_size, self.token_sizes[ax]), self._cfg.alphas[ax], device= self.device)\n",
    "        probs = torch._sample_dirichlet(concentration)\n",
    "        probs = einops.repeat(probs, f'b {ax} -> b {self.flat_token_pattern}', **self.token_sizes)\n",
    "        return probs.log()\n",
    "    \n",
    "    def get_masking_weights(self):\n",
    "        G = self.gumbel_noise((self.batch_size, self.num_tokens))\n",
    "        D = self.dirichlet_marginal('t')\n",
    "        return G + D\n",
    "\n",
    "    def get_frcst_weights(self):\n",
    "        step = torch.zeros((self.token_sizes['t'],), device=self.device)\n",
    "        step[:self._cfg.tau] = float('inf')\n",
    "        return einops.repeat(step, f't -> b {self.flat_token_pattern}', **self.token_sizes, b=self.batch_size)\n",
    "    \n",
    "    def get_visible_rate(self):\n",
    "        linear_grid = torch.linspace(0, 1, self.batch_size, device= self.device)\n",
    "        u = torch.rand((1,), device = self.device)\n",
    "        return (u + linear_grid) % 1 \n",
    "    \n",
    "    def get_history_rate(self):\n",
    "        return torch.full((self.batch_size,), self._cfg.tau / self.token_sizes['t'], device = self.device)\n",
    "            \n",
    "    def get_binary_mask(self, weights, rates):\n",
    "        k = (self.num_tokens * rates).long().clamp(1, self.num_tokens - 1).view(-1, 1)\n",
    "        index = weights.argsort(dim = -1, descending=True)\n",
    "        topk = self.flatland_index < k\n",
    "        binary = torch.zeros_like(topk, dtype=torch.bool).scatter(1, index, topk)\n",
    "        return binary, ~binary\n",
    "    \n",
    "    ### FORWARD\n",
    "    @property\n",
    "    def land_sea_mask(self):\n",
    "        lsm = torch.ones((1, self.field_sizes['h'], self.field_sizes['w']), device = self.device)\n",
    "        return einops.repeat(lsm, f'1 (h hh) (w ww) -> {self.flatland_pattern}', **self.patch_sizes, **self.token_sizes, b=self.batch_size)\n",
    "    \n",
    "    @property\n",
    "    def loss_weights(self):\n",
    "        w = torch.as_tensor(list(self._cfg.loss_weights.values()))\n",
    "        return einops.repeat(w, f'(v vv) -> {self.flatland_pattern}', **self.patch_sizes, **self.token_sizes, b=self.batch_size)\n",
    "\n",
    "    def forward(self, data, mode: str = 'prior'):\n",
    "        # tokens\n",
    "        data = data.to(self.device)\n",
    "        tokens = self.field_to_tokens(data)\n",
    "        \n",
    "        # masking\n",
    "        visible_rate = self.get_visible_rate() if mode == 'prior' else self.get_history_rate() \n",
    "        weights = self.get_masking_weights() if mode == 'prior' else self.get_frcst_weights()  \n",
    "        visible, masked = self.get_binary_mask(weights, visible_rate)\n",
    "        \n",
    "        # network\n",
    "        pred = self.network(tokens, visible, self.token_index)\n",
    "        pred = einops.rearrange(pred, '(b n) ... (d e) -> b ... d (n e)', d = tokens.size(-1), b = self.batch_size)\n",
    "        \n",
    "        # scoring rule\n",
    "        score = f_kernel_crps(tokens, pred) #* self.loss_weights * self.land_sea_mask # re-scale loss by variable and land-sea\n",
    "\n",
    "        # masked diffusion loss\n",
    "        score = score * (1 / (1 - visible_rate)).view(-1, 1, 1)\n",
    "        loss = score[masked].sum() / masked.sum()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3458a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MaskedField(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a3911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn((mf.batch_size, *mf.field_sizes.values()))\n",
    "loss = mf(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff721f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74b55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
