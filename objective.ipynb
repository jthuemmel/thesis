{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91298168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import math\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "from utils.config import NetworkConfig\n",
    "from utils.loss_fn import f_kernel_crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8f93ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4339d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WorldConfig:\n",
    "    field_layout: tuple\n",
    "    patch_layout: tuple\n",
    "    field_sizes: dict\n",
    "    patch_sizes: dict\n",
    "    batch_size: int\n",
    "    tau: int\n",
    "    alphas: dict\n",
    "    mask_range: tuple\n",
    "\n",
    "@dataclass\n",
    "class ConfigWrapper:\n",
    "    world : WorldConfig\n",
    "    network : NetworkConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72f0a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = NetworkConfig(\n",
    "    dim = 256, \n",
    "    num_layers=12, \n",
    "    dim_in = 4,\n",
    "    dim_out = 96,\n",
    "    dim_coords = 128,\n",
    "    wavelengths=[(1e-3, 1e2,), (1e-3, 1e2), (1e-3, 1e2,), (1e-3, 1e2,)], \n",
    "    num_features= 8, \n",
    "    num_latents=64)\n",
    "\n",
    "world_cfg = WorldConfig(\n",
    "    field_layout = ('v', 't', 'h', 'w'),\n",
    "    patch_layout = ('vv', 'tt', 'hh', 'ww'),\n",
    "    field_sizes = {'v': 8, 't': 36, 'h': 64, 'w': 120},\n",
    "    patch_sizes = {'vv': 1, 'tt': 6, 'hh': 8, 'ww': 10},\n",
    "    batch_size = 8,\n",
    "    tau = 2,\n",
    "    mask_range = (64, 4096),\n",
    "    alphas = {'t': 3.}  # Dirichlet prior concentration parameters\n",
    ")\n",
    "\n",
    "cfg = ConfigWrapper(\n",
    "    world = world_cfg,\n",
    "    network = model_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379b4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a24638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.components import *\n",
    "\n",
    "class WeatherField(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # embeddings\n",
    "        self.latent_embedding = torch.nn.Embedding(cfg.num_latents, cfg.dim)\n",
    "        self.world_embedding = ContinuousPositionalEmbedding(cfg.dim_coords, cfg.wavelengths, cfg.dim)\n",
    "\n",
    "        # linear projections\n",
    "        self.proj_in = SegmentLinear(cfg.dim_in, cfg.dim, cfg.num_features)\n",
    "        self.proj_out = SegmentLinear(cfg.dim, cfg.dim_out, cfg.num_features)\n",
    "\n",
    "        # Transformer blocks\n",
    "        self.encoder = torch.nn.ModuleList([TransformerBlock(cfg.dim, dim_heads=cfg.dim_heads) for _ in range(cfg.num_layers)])\n",
    "        self.decoder = TransformerBlock(cfg.dim, dim_heads=cfg.dim_heads, has_skip=False)\n",
    "        \n",
    "        # Initialization\n",
    "        self.apply(self.base_init)\n",
    "\n",
    "    @staticmethod\n",
    "    def base_init(m):\n",
    "        if isinstance(m, torch.nn.Linear):\n",
    "            torch.nn.init.trunc_normal_(m.weight, std = get_weight_std(m.weight))\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "        if isinstance(m, torch.nn.Embedding):\n",
    "            torch.nn.init.trunc_normal_(m.weight, std = get_weight_std(m.weight))\n",
    "\n",
    "        if isinstance(m, torch.nn.LayerNorm):\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "            if m.weight is not None:\n",
    "                torch.nn.init.ones_(m.weight)\n",
    "\n",
    "        if isinstance(m, ConditionalLayerNorm) and m.linear is not None:\n",
    "            torch.nn.init.trunc_normal_(m.linear.weight, std = 1e-8)\n",
    "\n",
    "    def forward(self, tokens, visible, coordinates):\n",
    "        batch = torch.arange(tokens.size(0), device=tokens.device).expand(tokens.size(0), -1) # index for fancy indexing\n",
    "        modality = coordinates[..., 0] # index for modality-wise linear layers\n",
    "        \n",
    "        # positional embedding for all available coordinates\n",
    "        world = self.world_embedding(coordinates)\n",
    "        \n",
    "        # embed visible values and add their positional code\n",
    "        src = self.proj_in(tokens[batch, visible], modality[batch, visible])\n",
    "        src = src + world[batch, visible]\n",
    "        \n",
    "        # update latents given src and latents\n",
    "        latents = self.latent_embedding.weight.expand(tokens.size(0), -1, -1)\n",
    "        for perceiver in self.encoder:\n",
    "            kv = torch.cat([src, latents], dim = 1)\n",
    "            latents = perceiver(latents, kv)\n",
    "\n",
    "        # update world given latents\n",
    "        out = self.decoder(world, latents)\n",
    "        out = self.proj_out(out, modality)\n",
    "        return out\n",
    "\n",
    "class MaskedField(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self._cfg = cfg.world\n",
    "        self.device_type: str = 'cpu'\n",
    "        self.device: torch.DeviceObjType = torch.device('cpu')\n",
    "        self.network = WeatherField(cfg.network)\n",
    "\n",
    "    ### SHAPES\n",
    "    @property # arrangement of axes in the unpatched field \n",
    "    def field_layout(self): \n",
    "        return self._cfg.field_layout\n",
    "    \n",
    "    @property # arrangement of axes in the patch dimension\n",
    "    def patch_layout(self): \n",
    "        return self._cfg.patch_layout\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self): \n",
    "        return self._cfg.batch_size\n",
    "\n",
    "    @property # field sizes per axis from config\n",
    "    def field_sizes(self): \n",
    "        return self._cfg.field_sizes\n",
    "\n",
    "    @property # patch sizes per axis from config\n",
    "    def patch_sizes(self): \n",
    "        return self._cfg.patch_sizes\n",
    "    \n",
    "    @property # patch counts per axis derived from field and patch sizes\n",
    "    def token_sizes(self): \n",
    "        return {ax: (self.field_sizes[ax] // self.patch_sizes[f'{ax*2}']) for ax in self.field_layout}\n",
    "    \n",
    "    @property # tuple of integers for the patched dimensions\n",
    "    def token_shape(self):\n",
    "        return tuple(self.token_sizes[ax] for ax in self.field_layout)\n",
    "    \n",
    "    @property # total number of patches in the flatland representation\n",
    "    def num_tokens(self): \n",
    "        return math.prod([self.token_sizes[t] for t in self.field_layout])\n",
    "\n",
    "    @property # total number of values in a single patch\n",
    "    def dim_tokens(self):  \n",
    "        return math.prod([self.patch_sizes[p] for p in self.patch_layout])\n",
    "    \n",
    "    @property # for fancy indexing along the batch dimension\n",
    "    def batch_index(self): \n",
    "        return torch.arange(self.batch_size, device = self.device).view(-1, 1)\n",
    "    \n",
    "    @property # per-axis indices for all patches\n",
    "    def coordinate_index(self):\n",
    "        return torch.stack(torch.unravel_index(torch.arange(self.num_tokens, device = self.device).expand(self.batch_size, -1), self.token_shape), dim=-1)\n",
    "\n",
    "    @property # einops pattern for the unpatched field\n",
    "    def field_pattern(self): \n",
    "        field = \" \".join([f\"({f} {p})\" for f, p in zip(self.field_layout, self.patch_layout)])\n",
    "        return f\"b {field} ...\"\n",
    "\n",
    "    @property # einops pattern for the flattened token dimension\n",
    "    def flat_token_pattern(self):\n",
    "        return f'({' '.join(self.field_layout)})'\n",
    "    \n",
    "    @property # einops pattern for the flattened patch dimension\n",
    "    def flat_patch_pattern(self):\n",
    "        return f'({' '.join(self.patch_layout)})'\n",
    "\n",
    "    @property # einops pattern for the patched flatland representation\n",
    "    def flatland_pattern(self): \n",
    "        return f'b {self.flat_token_pattern} {self.flat_patch_pattern} ...'\n",
    "    \n",
    "    ### TOKENIZATION\n",
    "    def field_to_tokens(self, field):\n",
    "        return einops.rearrange(field, f'{self.field_pattern} -> {self.flatland_pattern}', **self.patch_sizes)\n",
    "    \n",
    "    def tokens_to_field(self, patch):\n",
    "        return einops.rearrange(patch, f\"{self.flatland_pattern} -> {self.field_pattern}\", **self.token_sizes, **self.patch_sizes)\n",
    "\n",
    "    ### MASKING\n",
    "    def gumbel_noise(self, shape: tuple, eps: float = 1e-6):\n",
    "        u = torch.rand(shape, device = self.device).clamp(min=eps, max=1-eps)\n",
    "        return -torch.log(-torch.log(u))\n",
    "            \n",
    "    def dirichlet_marginal(self, ax: str):\n",
    "        concentration = torch.full((self.batch_size, self.token_sizes[ax]), self._cfg.alphas[ax], device= self.device)\n",
    "        probs = torch._sample_dirichlet(concentration)\n",
    "        probs = einops.repeat(probs, f'b {ax} -> {self.flat_token_pattern}', **self.token_sizes)\n",
    "        return probs.log()\n",
    "    \n",
    "    def get_frcst_mask(self):\n",
    "        k = int(self.num_tokens  * self._cfg.tau / self.token_sizes['t'])\n",
    "        step = torch.zeros((self.token_sizes['t'],), device=self.device)\n",
    "        step[:self._cfg.tau] = float('inf')\n",
    "        step = einops.repeat(step, f't -> b {self.flat_token_pattern}', **self.token_sizes, b=self.batch_size)\n",
    "        step = step.argsort(dim = -1, descending=True)\n",
    "        return step[..., :k], step[..., k:]\n",
    "            \n",
    "    def get_random_mask(self):\n",
    "        k = torch.randint(*self._cfg.mask_range, (1,), device = self.device)\n",
    "        G = self.gumbel_noise((self.batch_size, self.num_tokens))\n",
    "        factors = [G] + [self.dirichlet_marginal(ax) for ax in self._cfg.alphas.keys()]\n",
    "        score = einops.reduce(factors, f'factors ... -> ...', 'sum') \n",
    "        score = score.argsort(dim = -1, descending=True)\n",
    "        return score[..., :k], score[..., k:]\n",
    "    \n",
    "    ### FORWARD\n",
    "    @property\n",
    "    def land_sea_mask(self):\n",
    "        lsm = torch.ones((1, self.field_sizes['h'], self.field_sizes['w']), device = self.device)\n",
    "        return einops.repeat(lsm, f'1 (h hh) (w ww) -> {self.flatland_pattern}', **self.patch_sizes)\n",
    "    \n",
    "    @property\n",
    "    def loss_weights(self):\n",
    "        w = torch.as_tensor(self._cfg.loss_weights)\n",
    "        return einops.repeat(w, f'(v vv) -> {self.flatland_pattern}', **self.patch_sizes)\n",
    "\n",
    "    def forward(self, data, mode: str = 'prior'):\n",
    "        data = data.to(self.device)\n",
    "        tokens = self.field_to_tokens(data)\n",
    "        visible, masked = self.get_random_mask() if mode == 'prior' else self.get_frcst_mask()\n",
    "        \n",
    "        pred = self.network(tokens, visible, self.coordinate_index)\n",
    "\n",
    "        loss = f_kernel_crps(tokens, pred) * self.loss_weights * self.land_sea_mask # re-scale loss by variable and land-sea\n",
    "        loss = loss[self.batch_index, masked] #only calculate loss on masked tokens\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f3458a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MaskedField(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2a3911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn((mf.batch_size, mf.num_tokens, 4))\n",
    "mask, complement = mf.get_random_mask()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ff721f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mf.network(data, mask, mf.coordinate_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74b55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
